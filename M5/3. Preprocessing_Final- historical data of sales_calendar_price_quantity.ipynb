{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This program will melt the  preprocessed! calendar and sales files into a long table with all the original and encoded columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requires extensive CPU, Memory, and Time Resources.  \n",
    "#### Overrides data in the same directory. \n",
    "#### Back up data in the temp and data folders prior to running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "import sklearn as sk\n",
    "import category_encoders as ce\n",
    "import statsmodels as sm\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('temp/M5_preprocessed_sales-v1.csv', index_col=0)\n",
    "calendar_df = pd.read_csv('temp/M5_preprocessed_calendar-v1.csv', index_col=0, parse_dates=['date'])\n",
    "prices_df = pd.read_csv('data/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id_#</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>dept_id_1</th>\n",
       "      <th>dept_id_2</th>\n",
       "      <th>dept_id_3</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>2</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>4</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>5</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1956 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id_#        item_id    dept_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation          1  HOBBIES_1_001  HOBBIES_1   \n",
       "1  HOBBIES_1_002_CA_1_validation          2  HOBBIES_1_002  HOBBIES_1   \n",
       "2  HOBBIES_1_003_CA_1_validation          3  HOBBIES_1_003  HOBBIES_1   \n",
       "3  HOBBIES_1_004_CA_1_validation          4  HOBBIES_1_004  HOBBIES_1   \n",
       "4  HOBBIES_1_005_CA_1_validation          5  HOBBIES_1_005  HOBBIES_1   \n",
       "\n",
       "    cat_id store_id state_id  dept_id_1  dept_id_2  dept_id_3  ...  d_1904  \\\n",
       "0  HOBBIES     CA_1       CA          1          0          0  ...       1   \n",
       "1  HOBBIES     CA_1       CA          1          0          0  ...       0   \n",
       "2  HOBBIES     CA_1       CA          1          0          0  ...       2   \n",
       "3  HOBBIES     CA_1       CA          1          0          0  ...       1   \n",
       "4  HOBBIES     CA_1       CA          1          0          0  ...       2   \n",
       "\n",
       "   d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       3       0       1       1       1       3       0       1       1  \n",
       "1       0       0       0       0       1       0       0       0       0  \n",
       "2       1       2       1       1       1       0       1       1       1  \n",
       "3       0       5       4       1       0       1       3       7       2  \n",
       "4       1       1       0       1       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1956 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the sales data\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the first and the last day columns\n",
    "first_day = 'd_1'\n",
    "last_day = 'd_1913'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to melt start with day 1: 'd_1' column and end with 'd_1913'\n",
    "columns_sales = list(sales_df.columns[sales_df.columns.get_loc('d_1'):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorganize the columns and finalize the Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review the calendar data\n",
    "len(calendar_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year', 'd',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'day', 'Halloween', 'Christmas',\n",
       "       'EidAlAdha', 'Eid al-Fitr', 'OrthodoxChristmas', 'NewYear',\n",
       "       'Mother's day', 'ValentinesDay', 'Father's day', 'Thanksgiving',\n",
       "       'StPatricksDay', 'IndependenceDay', 'MemorialDay', 'PresidentsDay',\n",
       "       'MartinLutherKingDay', 'VeteransDay', 'LaborDay', 'ColumbusDay',\n",
       "       'LentStart', 'LentWeek2', 'OrthodoxEaster', 'Chanukah End',\n",
       "       'Ramadan starts', 'Easter', 'Cinco De Mayo', 'Pesach End', 'Purim End',\n",
       "       'NBAFinalsStart', 'NBAFinalsEnd', 'SuperBowl', 'Cultural', 'Religious',\n",
       "       'Sporting', 'National'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review the Sales columns upto the daily sales\n",
    "len(sales_df.columns[:sales_df.columns.get_loc('d_1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id_#', 'item_id', 'dept_id', 'cat_id', 'store_id',\n",
       "       'state_id', 'dept_id_1', 'dept_id_2', 'dept_id_3', 'dept_id_4',\n",
       "       'dept_id_5', 'dept_id_6', 'dept_id_7', 'cat_id_1', 'cat_id_2',\n",
       "       'cat_id_3', 'store_id_1', 'store_id_2', 'store_id_3', 'store_id_4',\n",
       "       'store_id_5', 'store_id_6', 'store_id_7', 'store_id_8', 'store_id_9',\n",
       "       'store_id_10', 'state_id_1', 'state_id_2', 'state_id_3', 'item_id_0',\n",
       "       'item_id_1', 'item_id_2', 'item_id_3', 'item_id_4', 'item_id_5',\n",
       "       'item_id_6', 'item_id_7', 'item_id_8', 'item_id_9', 'item_id_10',\n",
       "       'item_id_11', 'item_id_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.columns[:sales_df.columns.get_loc('d_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review the price data\n",
    "len(prices_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store_id', 'item_id', 'wm_yr_wk', 'sell_price'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate columns across three tables\n",
    "# ['store_id', 'item_id', 'wm_yr_wk', 'id']\n",
    "\n",
    "#Later we will add these features:\n",
    "# ['total_sale', 'quantity_sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = ['id','d', 'day','item_id_#', 'item_id','date', 'sell_price',\n",
    "          'dept_id', 'cat_id', 'store_id',\n",
    "          'wm_yr_wk', 'weekday', 'wday', 'month', 'year', \n",
    "          \n",
    "       'state_id', 'dept_id_1', 'dept_id_2', 'dept_id_3', 'dept_id_4',\n",
    "       'dept_id_5', 'dept_id_6', 'dept_id_7', 'cat_id_1', 'cat_id_2',\n",
    "       'cat_id_3', 'store_id_1', 'store_id_2', 'store_id_3', 'store_id_4',\n",
    "       'store_id_5', 'store_id_6', 'store_id_7', 'store_id_8', 'store_id_9',\n",
    "       'store_id_10', 'state_id_1', 'state_id_2', 'state_id_3', 'item_id_0',\n",
    "       'item_id_1', 'item_id_2', 'item_id_3', 'item_id_4', 'item_id_5',\n",
    "       'item_id_6', 'item_id_7', 'item_id_8', 'item_id_9', 'item_id_10',\n",
    "       'item_id_11', 'item_id_12',\n",
    " \n",
    "  \n",
    "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "       'snap_CA', 'snap_TX', 'snap_WI', \n",
    "       'Halloween', 'Christmas','EidAlAdha', 'Eid al-Fitr', 'OrthodoxChristmas',\n",
    "       'NewYear','Mother\\'s day', 'ValentinesDay', 'Father\\'s day', 'Thanksgiving',\n",
    "       'StPatricksDay', 'IndependenceDay', 'MemorialDay', 'PresidentsDay',\n",
    "       'MartinLutherKingDay', 'VeteransDay', 'LaborDay', 'ColumbusDay',\n",
    "       'LentStart', 'LentWeek2', 'OrthodoxEaster', 'Chanukah End',\n",
    "       'Ramadan starts', 'Easter', 'Cinco De Mayo', 'Pesach End', 'Purim End',\n",
    "       'NBAFinalsStart', 'NBAFinalsEnd', 'SuperBowl', 'Cultural', 'Religious',\n",
    "       'Sporting', 'National',\n",
    "         \n",
    "       'sell_price', 'total_sale', 'quantity_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "30485    0\n",
       "30486    0\n",
       "30487    0\n",
       "30488    0\n",
       "30489    0\n",
       "Name: d_1, Length: 30490, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.iloc[:,sales_df.columns.get_loc(first_day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the Sales_preprocessed and Calendar_preprocessed Tables on Day Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add sales price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store_id', 'item_id', 'wm_yr_wk', 'sell_price'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engineer the unique id's for each item in the price table\n",
    "prices_df['id'] = prices_df['item_id'] + '_' + prices_df['store_id']+ '_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize columns\n",
    "columns_final = schema.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply transformation to the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### takes the the daily sales data for each item from the sales file, daily calendar info from calendar file\n",
    "#### and gets the price info from sell_price file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id_#', 'item_id', 'dept_id', 'cat_id', 'store_id',\n",
       "       'state_id', 'dept_id_1', 'dept_id_2', 'dept_id_3', 'dept_id_4',\n",
       "       'dept_id_5', 'dept_id_6', 'dept_id_7', 'cat_id_1', 'cat_id_2',\n",
       "       'cat_id_3', 'store_id_1', 'store_id_2', 'store_id_3', 'store_id_4',\n",
       "       'store_id_5', 'store_id_6', 'store_id_7', 'store_id_8', 'store_id_9',\n",
       "       'store_id_10', 'state_id_1', 'state_id_2', 'state_id_3', 'item_id_0',\n",
       "       'item_id_1', 'item_id_2', 'item_id_3', 'item_id_4', 'item_id_5',\n",
       "       'item_id_6', 'item_id_7', 'item_id_8', 'item_id_9', 'item_id_10',\n",
       "       'item_id_11', 'item_id_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting just sales data\n",
    "items_for_sale = sales_df.iloc[:,:sales_df.columns.get_loc(first_day)]\n",
    "items_for_sale.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initiate the  dataframe\n",
    "df_final = pd.DataFrame()  # This is to store  the final merged data\n",
    "df_temp = pd.DataFrame()   #To store temporary data\n",
    "\n",
    "#determine the file path and the name\n",
    "file_name_prefix = 'temp/in_progress_preprocessed_data'\n",
    "file_format = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set packet sizes: each file will have certain number of days.\n",
    "\n",
    "start_date = int(input(\"What is the starting day: \"))   \n",
    "\n",
    "end_date = int(input(\"What is the last day: \")) \n",
    "\n",
    "\n",
    "step = 3   # set the number of days to include in each file\n",
    "\n",
    "packets = list(range(start_date+step,end_date,step)) + [end_date]\n",
    "\n",
    "indx_processed = [start_date-1]  #list of last day processed in each file\n",
    "\n",
    "suffix_end = '_' + str(start_date) + '_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 7, 10]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next step is expensive to run. Make sure to back up the files in the temp folder. This will override previous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to \"temp/in_progress_preprocessed_data\":\n",
      "\n",
      "Processed Day_1\n",
      "Processed Day_2\n",
      "Processed Day_3\n",
      "\n",
      "saved file:  temp/in_progress_preprocessed_data_1_4.csv\n",
      "Processed Day_4\n",
      "Processed Day_5\n",
      "Processed Day_6\n",
      "\n",
      "saved file:  temp/in_progress_preprocessed_data_5_7.csv\n",
      "Processed Day_7\n",
      "Processed Day_8\n",
      "Processed Day_9\n",
      "\n",
      "saved file:  temp/in_progress_preprocessed_data_8_10.csv\n",
      "Processed Day_10\n"
     ]
    }
   ],
   "source": [
    "i = start_date-1  #index of the starting day\n",
    "print(f'Saving data to \"{file_name_prefix}\":\\n')\n",
    "\n",
    "\n",
    "\n",
    "for col in calendar_df['d'][start_date-1:end_date]:    # iterate over days in the calendar df\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    ### Extracting the day column\n",
    "    \n",
    "    day = int(col.split('d_')[1])   #Extract the day number from col being iterated\n",
    "    #print(f\" #Extracted the day number from {col} being iterated\")\n",
    "    \n",
    "    \n",
    "    items_for_sale['day'] = day   #Adding the day # as a column\n",
    "    #print(\" #Adding the day # as a column\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    items_for_sale['quantity_sold'] = sales_df[col]  # Copy the day column from the sales \n",
    "    #print(\"# Copied the day columns from the sales_df\")\n",
    " \n",
    "    \n",
    "    items_sold_day = items_for_sale[ items_for_sale['quantity_sold'] > 0 ]  #filter the items sold on this date\n",
    "    #print(\"#filtered the items sold on this date\")\n",
    "\n",
    "\n",
    "    ### merging the calendar information \n",
    "\n",
    "    #filtering the calendar info for the day\n",
    "    calendar_info = calendar_df[calendar_df['d']==col] \n",
    "    #print('filtering the calendar info for the day')\n",
    "    \n",
    "    \n",
    "    ### merging the calendar information\n",
    "    items_sold_day_calendar = items_sold_day.merge(calendar_info, how='left', left_on='day', right_on='day')\n",
    "    #print('merging calendar info')\n",
    "    \n",
    "\n",
    "    ### merging with the selling price \n",
    "    temp_df = pd.merge(items_sold_day_calendar,prices_df[['id','wm_yr_wk','sell_price']], how='left', suffixes=['_x', '_y'])\n",
    "    #print('merging with the selling price')\n",
    "    \n",
    "    \n",
    "    #Calculate the total sale amount in $\n",
    "    temp_df['total_sale'] =  temp_df.sell_price * temp_df.quantity_sold    \n",
    "    #print('Calculate the total sale amount in $')\n",
    "    \n",
    "    \n",
    "    #Append the data from the current loop to file\n",
    "    df_temp = df_temp.append(temp_df[schema])\n",
    "    #print('Append the data from the current loop to file')  \n",
    "    \n",
    "\n",
    "    \n",
    "    #increment index:'i' by 1 to match the day processed\n",
    "    i+=1  \n",
    "    \n",
    "    ### Getting ready to export to csv\n",
    "    #### set up the file name \n",
    "    \n",
    "    # packets is the list of indexes when the temp df will be exported to a file\n",
    "    if (i) in packets: \n",
    "        \n",
    "        #setting up the file name suffix start : (file_name_sfxstart_sfxend)\n",
    "        if indx_processed[-1] == 0:  \n",
    "            suffix_start = '_1_'    ## first day is 1, therefore conditional for 0+1\n",
    "        \n",
    "        else:    \n",
    "            suffix_start = '_' + str(indx_processed[-1]+1) + '_'\n",
    "        \n",
    "        \n",
    "        # change i to string to be able to concat with the file name\n",
    "        suffix_end = str(i)\n",
    "        \n",
    "        ### Finalize the file name\n",
    "        file_name_suffix = suffix_start + suffix_end  \n",
    "        \n",
    "        ### combine with the data format\n",
    "        path = file_name_prefix + file_name_suffix + file_format\n",
    "        \n",
    "        df_temp.to_csv(path, mode='a', header=True, index_label=0)   #Append the data from the current loop to file\n",
    "        \n",
    "        print(f'Processed Day_{day}')\n",
    "        print(f\"\\nsaved file:  {path}\")\n",
    "        \n",
    "        \n",
    "        #Save the last day processed to index variable\n",
    "        indx_processed.append(i)\n",
    "        \n",
    "        #Restart the df_final to free up memory\n",
    "        df_temp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
